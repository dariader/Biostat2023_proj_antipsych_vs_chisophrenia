---
title: "EDA"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Список библиотек для установки, если их нет
libraries_to_install <- c("tidyverse", "ggplot2", "writexl", "openxlsx", "shiny", "kableExtra", "broom", "here", "TOC")

# Проверка и установка библиотек
for (library_name in libraries_to_install) {
  if (!requireNamespace(library_name, quietly = TRUE)) {
    install.packages(library_name, dependencies = TRUE)
  }
}

library(tidyverse)
library(ggplot2)
library(writexl)
library(openxlsx)
library(shiny)
library(kableExtra)
library(broom)
library(here)
```

# EDA

```{r}
path <- here("data", "Data_SAS.xlsx")
data <- readxl::read_xlsx(path, sheet = 2)
#data %>% glimpse()
#data %>% summary()
```



## Приводим данные к нужному виду

```{r}
# Копируем исходный датафрейм
data_filtered <- data

# Переводим числовые столбцы в числовой формат
numeric_columns <- c("age", "disease duration", "THF dose", "gait", "arm dropping",
                          "shoulder shaking", "elbow rigidity", "wrist rigidity", "head rotation",
                          "glabella tap", "tremor", "salivation", "akathisia", "Total score SAS",
                          "P1", "P2", "P3", "P4", "P5", "P6", "P7", "Positive scale",
                          "N1", "N2", "N3", "N4", "N5", "N6", "N7", "Negative scale",
                          "G1", "G2", "G3", "G4", "G5", "G6", "G7", "G8", "G9", "G10",
                          "G11", "G12", "G13", "G14", "G15", "G16", "General Psychopathology scale",
                          "Total score PANSS", "Verbal Memory", "ZVM", "Digit Sequencing", "ZDS",
                          "Token Motor Task", "ZMT", "Verbal Fluency", "ZVF", "Symbol Coding", "ZSC",
                          "Tower of London", "ZToL", "Comp Z")

# все десятичные разделители делаем точками
data_filtered[numeric_columns] <- lapply(data_filtered[numeric_columns], function(x) {
  as.numeric(gsub(",", ".", x))
})

# Переводим категориальные столбцы в факторы
factor_columns <- c("gender", "visit", "antipsychotic","antipsychotic dose", 
                    "course", "education", "smoke", "antipsychotic generation")

data_filtered[factor_columns] <- lapply(data_filtered[factor_columns], as_factor)

#data_filtered %>% glimpse
```

## Проверка шкал

Проверим, правильно ли посчитали SAS

```{r}
data_filtered %>%
  mutate(total_score_SAS_auto = rowSums(select(., gait:akathisia))) %>% 
  filter(`Total score SAS` != total_score_SAS_auto)%>% 
  select(id, `Total score SAS`, total_score_SAS_auto) 
```
Выявлены ошибки в двух строках.

Проверим, правильно ли посчитали PANSS
```{r}
# Создаем колонки
data_compare <- data_filtered %>%
  mutate(
    Positive_scale_auto = rowSums(select(., P1:P7)),
    Negative_scale_auto = rowSums(select(., N1:N7)),
    General_Psychopathology_scale_auto = rowSums(select(., G1:G16)),
    Total_score_PANSS_auto = Positive_scale_auto + Negative_scale_auto + General_Psychopathology_scale_auto
  )

# Сравниваем
differences_pos_scale <- data_compare %>%
  filter(`Positive scale` != Positive_scale_auto)

differences_neg_scale <- data_compare %>%
  filter(`Negative scale` != Negative_scale_auto)

differences_gen_psychopathology <- data_compare %>%
  filter(`General Psychopathology scale` != General_Psychopathology_scale_auto)

differences_total_panss <- data_compare %>%
  filter(`Total score PANSS` != Total_score_PANSS_auto)

```

```{r echo=FALSE}
# Выводим результаты
cat("Различия в Positive scale:\n")
print(differences_pos_scale[, c("id", "Positive scale", "Positive_scale_auto")])

cat("\nРазличия в Negative scale:\n")
print(differences_neg_scale[, c("id", "Negative scale", "Negative_scale_auto")])

cat("\nРазличия в General Psychopathology scale:\n")
print(differences_gen_psychopathology[, c("id", "General Psychopathology scale", "General_Psychopathology_scale_auto")])

cat("\nРазличия в Total score PANSS:\n")
print(differences_total_panss[, c("id", "Total score PANSS", "Total_score_PANSS_auto")])
```

Проверка шкалы BACS.

```{r}
# Код для автоматического расчета Z-баллов. Z-баллы рассчитывались с использованием норматимвных для российской популяции [Саркисян, Г. Р., Гурович, И. Я., & Киф, Р. С. (2010). Нормативные данные для российской популяции и стандартизация шкалы «Краткая оценка когнитивных функций у пациентов с шизофренией» (BACS). Социальная и клиническая психиатрия, 20 (3), 13-19.]

data_compare <- data_filtered %>%
  mutate(
    ZVM_auto = case_when(
      gender == 'м' & age < 30 ~ round((`Verbal Memory` - 49.55) / 7.1, 2),
      gender == 'м' & age > 29 & age < 40 ~ round((`Verbal Memory` - 48.67) / 7.1, 2),
      gender == 'м' & age > 39 & age < 50 ~ round((`Verbal Memory` - 44.44) / 5.47, 2),
      gender == 'ж' & age < 30 ~ round((`Verbal Memory` - 50.52) / 7.94, 2),
      gender == 'ж' & age > 29 & age < 40 ~ round((`Verbal Memory` - 49.77) / 7.25, 2),
      gender == 'ж' & age > 39 & age < 50 ~ round((`Verbal Memory` - 47.00) / 6.35, 2),
      gender == 'ж' & age > 49 & age < 60 ~ round((`Verbal Memory` - 44.33) / 7.32, 2),
      TRUE ~ NA_real_
    ),
    ZDS_auto = case_when(
      gender == 'м' & age < 30 ~ round((`Digit Sequencing` - 21.8) / 2.57, 2),
      gender == 'м' & age > 29 & age < 40 ~ round((`Digit Sequencing` - 22.14) / 3.35, 2),
      gender == 'м' & age > 39 & age < 50 ~ round((`Digit Sequencing` - 20.07) / 3.33, 2),
      gender == 'ж' & age < 30 ~ round((`Digit Sequencing` - 20.24) / 3.50, 2),
      gender == 'ж' & age > 29 & age < 40 ~ round((`Digit Sequencing` - 21.59) / 3.14, 2),
      gender == 'ж' & age > 39 & age < 50 ~ round((`Digit Sequencing` - 20.60) / 3.56, 2),
      gender == 'ж' & age > 49 & age < 60 ~ round((`Digit Sequencing` - 17.90) / 3.69, 2),
      TRUE ~ NA_real_
    ),
    ZMT_auto = case_when(
      gender == 'м' & age < 30 ~ round((`Token Motor Task` - 74.7) / 8.8, 2),
      gender == 'м' & age > 29 & age < 40 ~ round((`Token Motor Task` - 71.43) / 12.15, 2),
      gender == 'м' & age > 39 & age < 50 ~ round((`Token Motor Task` - 74.30) / 11.58, 2),
      gender == 'ж' & age < 30 ~ round((`Token Motor Task` - 68.57) / 9.36, 2),
      gender == 'ж' & age > 29 & age < 40 ~ round((`Token Motor Task` - 72.18) / 8.86, 2),
      gender == 'ж' & age > 39 & age < 50 ~ round((`Token Motor Task` - 71.6) / 12.64, 2),
      gender == 'ж' & age > 49 & age < 60 ~ round((`Token Motor Task` - 68.86) / 11.65, 2),
      TRUE ~ NA_real_
    ),
    ZVF_auto = case_when(
      gender == 'м' & age < 30 ~ round((`Verbal Fluency` - 58.4) / 9.46, 2),
      gender == 'м' & age > 29 & age < 40 ~ round((`Verbal Fluency` - 56.48) / 14.04, 2),
      gender == 'м' & age > 39 & age < 50 ~ round((`Verbal Fluency` - 62.00) / 16.76, 2),
      gender == 'ж' & age < 30 ~ round((`Verbal Fluency` - 54.8) / 14.53, 2),
      gender == 'ж' & age > 29 & age < 40 ~ round((`Verbal Fluency` - 60.45) / 11.05, 2),
      gender == 'ж' & age > 39 & age < 50 ~ round((`Verbal Fluency` - 58.2) / 10.7, 2),
      gender == 'ж' & age > 49 & age < 60 ~ round((`Verbal Fluency` - 58.29) / 10.79, 2),
      TRUE ~ NA_real_
    ),
    ZSC_auto = case_when(
      gender == 'м' & age < 30 ~ round((`Symbol Coding` - 61.95) / 8.06, 2),
      gender == 'м' & age > 29 & age < 40 ~ round((`Symbol Coding` - 61.24) / 10.73, 2),
      gender == 'м' & age > 39 & age < 50 ~ round((`Symbol Coding` - 54.35) / 6.61, 2),
      gender == 'ж' & age < 30 ~ round((`Symbol Coding` - 65.71) / 6.09, 2),
      gender == 'ж' & age > 29 & age < 40 ~ round((`Symbol Coding` - 60.86) / 8.74, 2),
      gender == 'ж' & age > 39 & age < 50 ~ round((`Symbol Coding` - 57.4) / 7.55, 2),
      gender == 'ж' & age > 49 & age < 60 ~ round((`Symbol Coding` - 50.1) / 10.24, 2),
      TRUE ~ NA_real_
    ),
    ZToL_auto = case_when(
      gender == 'м' & age < 30 ~ round((`Tower of London` - 18.45) / 1.82, 2),
      gender == 'м' & age > 29 & age < 40 ~ round((`Tower of London` - 19.1) / 1.67, 2),
      gender == 'м' & age > 39 & age < 50 ~ round((`Tower of London` - 18.35) / 2.98, 2),
      gender == 'ж' & age < 30 ~ round((`Tower of London` - 17.67) / 1.93, 2),
      gender == 'ж' & age > 29 & age < 40 ~ round((`Tower of London` - 17.64) / 1.71, 2),
      gender == 'ж' & age > 39 & age < 50 ~ round((`Tower of London` - 17.4) / 1.76, 2),
      gender == 'ж' & age > 49 & age < 60 ~ round((`Tower of London` - 16.48) / 2.36, 2),
      TRUE ~ NA_real_
    )
  )

data_compare <- data_compare %>% mutate(
  Comp_Z_auto = round(rowSums(select(., ZVM_auto:ZToL_auto))/ 3.96, 2))
```

```{r}
# Сравниваем
differences_ZVM <- data_compare %>%
  filter(ZVM_auto != ZVM)

differences_ZDS <- data_compare %>%
  filter(ZDS_auto != ZDS)

differences_ZMT <- data_compare %>%
  filter(ZMT_auto != ZMT)

differences_ZVF <- data_compare %>%
  filter(ZVF_auto != ZVF)

differences_ZSC <- data_compare %>%
  filter(ZSC_auto != ZSC)

differences_ZToL <- data_compare %>%
  filter(ZToL_auto != ZToL)

differences_Comp_Z <- data_compare %>%
  filter(Comp_Z_auto != `Comp Z`)
```

```{r echo=FALSE}
# Выводим результаты
cat("Различия в ZVM:\n")
print(differences_ZVM[, c("id", "ZVM", "ZVM_auto")])

cat("\nРазличия в ZDS:\n")
print(differences_ZDS[, c("id", "ZDS", "ZDS_auto")])

cat("\nРазличия в ZMT:\n")
print(differences_ZMT[, c("id", "ZMT", "ZMT_auto")])

cat("\nРазличия в ZVF:\n")
print(differences_ZVF[, c("id", "ZVF", "ZVF_auto")])

cat("Различия в ZSC:\n")
print(differences_ZSC[, c("id", "ZSC", "ZSC_auto")])

cat("Различия в ZToL:\n")
print(differences_ZToL[, c("id", "ZToL", "ZToL_auto")])

cat("Различия в Comp Z:\n")
print(differences_Comp_Z[, c("id", "Comp Z", "Comp_Z_auto")])
```


Выявлены ошибки в Total score SAS, Positive scale, Negative scale, General Psychopathology scale, Total score PANSS.
Так же выявлены ошибки во всех BACS.


## Испрвление ошибок
Для замены данных правильными, создан скрипт preprocessing.R: 

- Исправиляет найденные ошибки в шкалах.

- Добавляет 5-факторную модель.

- Добавляет хлорпромазиновый эквивалент.

- Создает Data_SAS_fixed.xlsx в _misc.

```{r}
path <- here("scripts/0_preprocessing", "preprocessing.R")
source(path)
path <- here("data", "Data_SAS.xlsx")
data_filtered <- preprocessing(path)
```

## EDA - исправленные данные

```{r}
# data_filtered %>%
#  glimpse()
```


EDA с помощью Shiny

```{r eval=FALSE}
path <- here("scripts/1_eda", "eda_shiny_func.R")
source(path)
eda_shiny(data_filtered)
```
# Динамика

Исследуем изменение количественных переменных между визитами используя:

- Тест Шапиро-Уилка для определение нормальности распределения. Укажем в normality_result.

- t-тест для зависимых выборок (paired=TRUE, $\alpha = 0.05$). Укажем значимость в t_significant_flag. 

- тест Уилкоксона для парных данных ($\alpha = 0.05$). Укажем значимость в wilcoxon_significant_flag 

```{r}
# Указываем переменные, для которых хотим провести t-тест
selected_variables <- data_filtered %>% select_if(is.numeric) %>% names()

# Проводим t-тест и тест на нормальность для каждой переменной
alpha = 0.05  # Устанавливаем уровень значимости
test_results <- lapply(selected_variables, function(variable) {
  # Проводим тест на нормальность
  normality_test_result <- shapiro.test(data_filtered[[variable]])
  
  # Проводим t-тест независимо от результата теста на нормальность
  visit_1 <- data_filtered %>% 
    filter(visit == 1) %>% 
    pull(variable)
  visit_2 <- data_filtered %>% 
    filter(visit == 2) %>% 
    pull(variable)
  test_result <- t.test(visit_1, visit_2, paired=TRUE)
  
  # Собираем результаты в data frame
  result_df <- data.frame(
    Variable = variable,
    t_value = test_result$statistic,
    t_p_value = test_result$p.value,
    t_significant_flag = ifelse(test_result$p.value < alpha, "1", "0"),
    normality_p_value = normality_test_result$p.value,
    normality_result = ifelse(normality_test_result$p.value > 0.05, "Normal", "Not normal")
  )
  return(result_df)
})

# Объединяем результаты
test_results <- bind_rows(test_results)

# Добавляем тест Уилкоксона к результатам
wilcoxon_test_result <- lapply(selected_variables, function(variable) {
  wilcoxon_result <- wilcox.test(data_filtered[[variable]] ~ data_filtered$visit)
  result_df <- data.frame(
    Variable = variable,
    wilcoxon_statistic = wilcoxon_result$statistic,
    wilcoxon_p_value = wilcoxon_result$p.value,
    wilcoxon_significant_flag = ifelse(wilcoxon_result$p.value < alpha, "1", "0")
  )
  return(result_df)
})

# Объединяем результаты Уилкоксона с предыдущими результатами
wilcoxon_test_result <- bind_rows(wilcoxon_test_result)
test_results <- left_join(test_results, wilcoxon_test_result, by = "Variable")

# Выводим результаты
test_results %>% 
  kable(format = "html") %>%
  kable_styling("striped", full_width = FALSE)
```


Только значимые:

```{r}
significant_variables <- test_results %>% 
  filter(t_significant_flag == 1 | wilcoxon_significant_flag == 1)
significant_variables %>% 
  select(Variable, t_significant_flag, wilcoxon_significant_flag, normality_result) %>% 
  kable(format = "html") %>%
  kable_styling("striped", full_width = FALSE)
```

Создадим датафрейм, содержащие разницу количественных показателей между визитами.

```{r}
# Выбираем только числовые переменные
selected_variables <- data_filtered %>%
  select_if(is.numeric) %>% 
  names()

# переменные которые не нужно вычитать
add_df <- data_filtered %>% 
  filter(visit == 1) %>% 
  select(id, age, `disease duration`, `THF dose`, CPZE)

# Создаем новый датафрейм для хранения разницы
difference_df <- data_filtered %>%
  select(id, visit, all_of(selected_variables)) %>%
  group_by(id) %>%
  summarise(across(selected_variables, ~diff(.))) %>% 
  mutate(age = add_df$age,
         `disease duration` = add_df$`disease duration`,
         `THF dose` = add_df$`THF dose`, 
         CPZE = add_df$CPZE
         ) %>% 
  rename_with(~paste0(., "_dif"), -c(id, age, `disease duration`, `THF dose`, CPZE))  # Добавляем суффикс "_dif" 
difference_df
```

```{r}
difference_df %>% str()
```
 Визуализируем: 
 
```{r}
difference_df %>%
  gather(variable, value, -id) %>%
  group_by(variable) %>%
  summarise(mean_value = mean(value, na.rm = TRUE)) %>%
  filter(grepl("_dif$", variable)) %>%
  mutate(variable = gsub("_dif$", "", variable)) %>%
  ggplot(aes(x = variable, y = mean_value)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  labs(title = "Средние отклонение переменных",
       x = "Переменные",
       y = "Среднее отклонение") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```
Тоже самое более кратко.

```{r}
difference_df %>%
  gather(variable, value, -id) %>%
  filter(!grepl("G[1-9]|N[1-7]|P[1-7]_dif$", variable)) %>%
  group_by(variable) %>%
  summarise(mean_value = mean(value, na.rm = TRUE)) %>%
  filter(grepl("_dif$", variable)) %>%
  mutate(variable = gsub("_dif$", "", variable)) %>%
  ggplot(aes(x = variable, y = mean_value, fill = factor(sign(mean_value)))) +
  geom_bar(stat = "identity", color = "black") +
  scale_fill_manual(values = c("blue", "gray", "red"), name = "Знак", labels = c("Отрицательное", "Ноль", "Положительное")) +
  labs(title = "Средние отклонение переменных",
       x = "Переменные",
       y = "Среднее отклонение") +
  theme_minimal() +
  guides(fill = FALSE) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

EDA difference_df в shiny доступна только для числовых переменнных.

Доступна только вкладка "Числовые переменные" без разбития по visit.

```{r eval=FALSE}
path <- here("scripts/1_eda", "eda_shiny_func.R")
source(path)
eda_shiny(difference_df)
```

## Строим модель

### Первые модели

Простая модель, включающая только `Total score SAS_dif`, `Total score PANSS_dif`. Предсказываем  `Comp Z_dif`

```{r}
lm(`Comp Z_dif` ~ `Total score SAS_dif` + `Total score PANSS_dif`, data=difference_df) %>% 
  summary()
```

Модель получается лучше, если оставить только `Total score SAS_dif`

```{r}
lm(`Comp Z_dif` ~ `Total score SAS_dif`, data=difference_df) %>% 
  summary()
```

Теперь попробуем построить сложную модель, пусть функция step разбирается. Установим trace=0, чтобы увидеть только последнюю модель.

```{r}
# уберем линейно зависимые переменные
selected_data <- difference_df %>% 
  select(-id, -excitment_dif, -cognitive_dif, -depression_dif , 
         -starts_with('N'), -starts_with('P'), -starts_with('G'), -starts_with('Z'))
lm(`Comp Z_dif` ~ ., data=selected_data) %>% 
  step(trace=0) %>%
  summary()
```
### Модель для Comp Z_dif

Исключим так же `Verbal Memory`, `Digit Sequencing`, `Token Motor Task`, `Verbal Fluency`, `Symbol Coding`, `Tower of London`.

```{r}
selected_data <- difference_df %>% 
  select(-id, -excitment_dif, -cognitive_dif, -depression_dif , 
         -starts_with('N'), -starts_with('P'), -starts_with('G'), -starts_with('Z')) %>% 
  select(-`Verbal Memory_dif`, -`Digit Sequencing_dif`, 
         -`Token Motor Task_dif`, -`Verbal Fluency_dif`, -`Symbol Coding_dif`, -`Tower of London_dif`)

lm(`Comp Z_dif` ~ ., data=selected_data) %>% 
  step(trace=0) %>% 
  summary()
```
Модель объясняет примерно 23.22% дисперсии (Multiple R-squared:  0.2322,	Adjusted R-squared:  0.1695).

### 5-факторная модель PANSS

Теперь используем 5-факторную модель PANSS.
```{r}
selected_data <- difference_df %>% 
  select(-id, -starts_with(c("N", "P", "G", "Z")), negative_dif, positive_dif, CPZE) %>% 
  select(-`Verbal Memory_dif`, -`Digit Sequencing_dif`, -`Token Motor Task_dif`, 
         -`Verbal Fluency_dif`, -`Symbol Coding_dif`, -`Tower of London_dif`)

lm(`Comp Z_dif` ~ ., data = selected_data) %>% 
  step(trace=0) %>% 
  summary()
```
Модель объясняет примерно 41.49% дисперсии (Multiple R-squared:  0.4149,	Adjusted R-squared:  0.3109).

Эта же модель с подробным описанием.
```{r}
model <- lm(`Comp Z_dif` ~ `shoulder shaking_dif` + `elbow rigidity_dif` + `wrist rigidity_dif` + salivation_dif +
     `Total score SAS_dif` + `Total score PANSS_dif` + cognitive_dif + depression_dif, data=selected_data)
tidy_results <- tidy(model)
glance_results <- glance(model) %>% 
  select(r.squared, adj.r.squared, sigma, logLik, AIC, BIC, df.residual, nobs)
results <- bind_cols(tidy_results, glance_results)
results %>%
  kable("html") %>%
  kable_styling("striped", full_width = FALSE)
```

Здесь можно поразвлекаться с моделями.
```{r}
lm(`Comp Z_dif` ~ `shoulder shaking_dif` + `elbow rigidity_dif` + `wrist rigidity_dif` +
    salivation_dif + `Total score SAS_dif` + `Total score PANSS_dif` + cognitive_dif + 
    depression_dif, data=selected_data) %>% 
  summary()
```
### Другая модель (ZVM_dif, ZSC_dif, ZVF_dif, ZDS_dif, ZToL_dif, ZMT_dif)

Исключим так же `Comp Z_dif`, но добавим ZVM_dif, ZSC_dif, ZVF_dif, ZDS_dif, ZToL_dif, ZMT_dif.

1. Предсказываем ZVM_dif. Используем функцию step().

```{r}
selected_data <- difference_df %>% 
  select(-id, -excitment_dif, -cognitive_dif, -depression_dif , 
         -starts_with('N'), -starts_with('P'), -starts_with('G'), -starts_with('Z'), ZVM_dif) %>% 
  select(-`Verbal Memory_dif`, -`Digit Sequencing_dif`, 
         -`Token Motor Task_dif`, -`Verbal Fluency_dif`, -`Symbol Coding_dif`, -`Tower of London_dif`) %>% 
  select(-`Comp Z_dif`)

lm(ZVM_dif ~ ., data=selected_data) %>% 
  step(trace=0) %>% 
  summary()
```

Multiple R-squared:  0.09264,	Adjusted R-squared:  0.05706

2. Предсказываем ZSC_dif. Используем функцию step().

```{r}
selected_data <- difference_df %>% 
  select(-id, -excitment_dif, -cognitive_dif, -depression_dif , 
         -starts_with('N'), -starts_with('P'), -starts_with('G'), -starts_with('Z'), ZSC_dif) %>% 
  select(-`Verbal Memory_dif`, -`Digit Sequencing_dif`, 
         -`Token Motor Task_dif`, -`Verbal Fluency_dif`, -`Symbol Coding_dif`, -`Tower of London_dif`) %>% 
  select(-`Comp Z_dif`)

lm(ZSC_dif ~ ., data=selected_data) %>% 
  step(trace=0) %>% 
  summary()
```

Multiple R-squared:  0.1565,	Adjusted R-squared:  0.1234 

3. Предсказываем ZVF_dif. Используем функцию step().

```{r}
selected_data <- difference_df %>% 
  select(-id, -excitment_dif, -cognitive_dif, -depression_dif , 
         -starts_with('N'), -starts_with('P'), -starts_with('G'), -starts_with('Z'), ZVF_dif) %>% 
  select(-`Verbal Memory_dif`, -`Digit Sequencing_dif`, 
         -`Token Motor Task_dif`, -`Verbal Fluency_dif`, -`Symbol Coding_dif`, -`Tower of London_dif`) %>% 
  select(-`Comp Z_dif`)

lm(ZVF_dif ~ ., data=selected_data) %>% 
  step(trace=0) %>% 
  summary()
```

Multiple R-squared:  0.2015,	Adjusted R-squared:  0.1536 

4. Предсказываем ZDS_dif. Используем функцию step().

```{r}
selected_data <- difference_df %>% 
  select(-id, -excitment_dif, -cognitive_dif, -depression_dif , 
         -starts_with('N'), -starts_with('P'), -starts_with('G'), -starts_with('Z'), ZDS_dif) %>% 
  select(-`Verbal Memory_dif`, -`Digit Sequencing_dif`, 
         -`Token Motor Task_dif`, -`Verbal Fluency_dif`, -`Symbol Coding_dif`, -`Tower of London_dif`) %>% 
  select(-`Comp Z_dif`)

lm(ZDS_dif ~ ., data=selected_data) %>% 
  step(trace=0) %>% summary()
```

Multiple R-squared:  0.1164,	Adjusted R-squared:  0.08172 

5. Предсказываем ZToL_dif. Используем функцию step().

```{r}
selected_data <- difference_df %>% 
  select(-id, -excitment_dif, -cognitive_dif, -depression_dif , 
         -starts_with('N'), -starts_with('P'), -starts_with('G'), -starts_with('Z'), ZToL_dif) %>% 
  select(-`Verbal Memory_dif`, -`Digit Sequencing_dif`, 
         -`Token Motor Task_dif`, -`Verbal Fluency_dif`, -`Symbol Coding_dif`, -`Tower of London_dif`) %>% 
  select(-`Comp Z_dif`)

lm(ZToL_dif ~ ., data=selected_data) %>% 
  step(trace=0) %>% summary()
```
Multiple R-squared:  0.2223,	Adjusted R-squared:  0.1588

6. Предсказываем ZMT_dif. Используем функцию step().

```{r}
selected_data <- difference_df %>% 
  select(-id, -excitment_dif, -cognitive_dif, -depression_dif , 
         -starts_with('N'), -starts_with('P'), -starts_with('G'), -starts_with('Z'), ZMT_dif) %>% 
  select(-`Verbal Memory_dif`, -`Digit Sequencing_dif`, 
         -`Token Motor Task_dif`, -`Verbal Fluency_dif`, -`Symbol Coding_dif`, -`Tower of London_dif`) %>% 
  select(-`Comp Z_dif`)

lm(ZMT_dif ~ ., data=selected_data) %>% 
  step(trace=0) %>% summary()
```

Multiple R-squared:  0.4085,	Adjusted R-squared:  0.2536 

### Модели по отдельным визитам

visit = 1

```{r}
selected_data <- data_filtered %>%
  filter(visit == 1) %>% 
  select(-id, -visit) %>% 
  select(-excitment, -cognitive, -depression, 
         -starts_with('N'), -starts_with('P'), -starts_with('G'), -starts_with('Z'), gender, gait) %>% 
  select(-`Verbal Memory`, -`Digit Sequencing`, 
         -`Token Motor Task`, -`Verbal Fluency`, -`Symbol Coding`, -`Tower of London`)
  
lm(`Comp Z` ~ ., data=selected_data) %>% 
  step(trace=0) %>% summary()
```
Multiple R-squared:  0.8786,	Adjusted R-squared:  0.1958

visit = 2

```{r}
selected_data <- data_filtered %>%
  filter(visit == 2) %>% 
  select(-id, -visit) %>% 
  select(-excitment, -cognitive, -depression, 
         -starts_with('N'), -starts_with('P'), -starts_with('G'), -starts_with('Z'), gender, gait) %>% 
  select(-`Verbal Memory`, -`Digit Sequencing`, 
         -`Token Motor Task`, -`Verbal Fluency`, -`Symbol Coding`, -`Tower of London`)
  
lm(`Comp Z` ~ ., data=selected_data) %>% 
  step(trace=0) %>% summary()
```
Multiple R-squared:  0.9109,	Adjusted R-squared:  0.6367

### Разбиваем на группы по ответу на терапию

```{r}
divide_by_treat_resp <- data_filtered %>%
  filter(visit %in% c('1', '2')) %>%
  group_by(id) %>%
  mutate(
    percentage_change = ((as.numeric(`Total score PANSS`[visit == '1']) - as.numeric(`Total score PANSS`[visit == '2'])) / as.numeric(`Total score PANSS`[visit == '1'])) * 100
  ) %>% 
  ungroup()

divide_by_treat_resp <- divide_by_treat_resp %>% 
  mutate(
  treat_resp = case_when(
    percentage_change < 15 ~ 0, # неответившие на терапию
    percentage_change >= 15 & percentage_change <= 20 ~ 1, # с недостаточным ответом
    percentage_change > 20 ~ 2, # ответившие на терапию
    TRUE ~ NA_real_
  )
)
divide_by_treat_resp %>% 
  ggplot() + 
  aes(treat_resp) +
  geom_histogram(binwidth = 1) +
  theme_minimal()
```
### Модели с добавлением ответа на терапию

Без разбития на визиты

```{r}
selected_data <- divide_by_treat_resp %>%
  select(-id) %>% 
  select(-excitment, -cognitive, -depression, 
         -starts_with('N'), -starts_with('P'), -starts_with('G'), -starts_with('Z'), gender, gait) %>% 
  select(-`Verbal Memory`, -`Digit Sequencing`, 
         -`Token Motor Task`, -`Verbal Fluency`, -`Symbol Coding`, -`Tower of London`)

lm(`Comp Z` ~ ., data=selected_data) %>% 
  step(trace=0) %>% summary()
```

Multiple R-squared:  0.8284,	Adjusted R-squared:  0.7039

visit = 1 

```{r}
selected_data <- divide_by_treat_resp %>%
  filter(visit == 1) %>% 
  select(-id, -visit) %>% 
  select(-excitment, -cognitive, -depression, 
         -starts_with('N'), -starts_with('P'), -starts_with('G'), -starts_with('Z'), gender, gait) %>% 
  select(-`Verbal Memory`, -`Digit Sequencing`, 
         -`Token Motor Task`, -`Verbal Fluency`, -`Symbol Coding`, -`Tower of London`)
  
lm(`Comp Z` ~ ., data=selected_data) %>% 
  step(trace=0) %>% summary()
```
Multiple R-squared:  0.8867,	Adjusted R-squared:  0.1422

visit = 2

```{r}
selected_data <- divide_by_treat_resp %>%
  filter(visit == 2) %>% 
  select(-id, -visit) %>% 
  select(-excitment, -cognitive, -depression, 
         -starts_with('N'), -starts_with('P'), -starts_with('G'), -starts_with('Z'), gender, gait) %>% 
  select(-`Verbal Memory`, -`Digit Sequencing`, 
         -`Token Motor Task`, -`Verbal Fluency`, -`Symbol Coding`, -`Tower of London`)
  
lm(`Comp Z` ~ ., data=selected_data) %>% 
  step(trace=0) %>% summary()
```
Multiple R-squared:  0.9186,	Adjusted R-squared:  0.608 
