---
title: "EDA"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
  word_document:
    toc: true
    toc_depth: '3'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Список библиотек для установки, если их нет
libraries_to_install <- c("tidyverse", "ggplot2", "writexl", "openxlsx", "shiny", "kableExtra", "broom", "here", "TOC", "psych", "lme4", "lmerTest", "broom")

# Проверка и установка библиотек
for (library_name in libraries_to_install) {
  if (!requireNamespace(library_name, quietly = TRUE)) {
    install.packages(library_name, dependencies = TRUE)
  }
}

library(tidyverse)
library(ggplot2)
library(writexl)
library(openxlsx)
library(shiny)
library(kableExtra)
library(broom)
library(here)
library(psych)
library(lme4)
library(lmerTest)
library(broom)
```

# EDA

```{r}
path <- here("data", "Data_SAS.xlsx")
data <- readxl::read_xlsx(path, sheet = 2)
#data %>% glimpse()
#data %>% summary()
```



## Приводим данные к нужному виду

```{r}
# Копируем исходный датафрейм
data_filtered <- data

# Переводим числовые столбцы в числовой формат
numeric_columns <- c("age", "disease duration", "THF dose", "gait", "arm dropping",
                          "shoulder shaking", "elbow rigidity", "wrist rigidity", "head rotation",
                          "glabella tap", "tremor", "salivation", "akathisia", "Total score SAS",
                          "P1", "P2", "P3", "P4", "P5", "P6", "P7", "Positive scale",
                          "N1", "N2", "N3", "N4", "N5", "N6", "N7", "Negative scale",
                          "G1", "G2", "G3", "G4", "G5", "G6", "G7", "G8", "G9", "G10",
                          "G11", "G12", "G13", "G14", "G15", "G16", "General Psychopathology scale",
                          "Total score PANSS", "Verbal Memory", "ZVM", "Digit Sequencing", "ZDS",
                          "Token Motor Task", "ZMT", "Verbal Fluency", "ZVF", "Symbol Coding", "ZSC",
                          "Tower of London", "ZToL", "Comp Z")

# все десятичные разделители делаем точками
data_filtered[numeric_columns] <- lapply(data_filtered[numeric_columns], function(x) {
  as.numeric(gsub(",", ".", x))
})

# Переводим категориальные столбцы в факторы
factor_columns <- c("gender", "visit", "antipsychotic","antipsychotic dose", 
                    "course", "education", "smoke", "antipsychotic generation")

data_filtered[factor_columns] <- lapply(data_filtered[factor_columns], as_factor)

#data_filtered %>% glimpse
```



## Проверка шкал

Проверим, правильно ли посчитали SAS

```{r}
data_filtered %>%
  mutate(total_score_SAS_auto = rowSums(select(., gait:akathisia))) %>% 
  filter(`Total score SAS` != total_score_SAS_auto)%>% 
  select(id, `Total score SAS`, total_score_SAS_auto) 
```
Выявлены ошибки в двух строках.

Проверим, правильно ли посчитали PANSS
```{r}
# Создаем колонки
data_compare <- data_filtered %>%
  mutate(
    Positive_scale_auto = rowSums(select(., P1:P7)),
    Negative_scale_auto = rowSums(select(., N1:N7)),
    General_Psychopathology_scale_auto = rowSums(select(., G1:G16)),
    Total_score_PANSS_auto = Positive_scale_auto + Negative_scale_auto + General_Psychopathology_scale_auto
  )

# Сравниваем
differences_pos_scale <- data_compare %>%
  filter(`Positive scale` != Positive_scale_auto)

differences_neg_scale <- data_compare %>%
  filter(`Negative scale` != Negative_scale_auto)

differences_gen_psychopathology <- data_compare %>%
  filter(`General Psychopathology scale` != General_Psychopathology_scale_auto)

differences_total_panss <- data_compare %>%
  filter(`Total score PANSS` != Total_score_PANSS_auto)

```

```{r echo=FALSE}
# Выводим результаты
cat("Различия в Positive scale:\n")
print(differences_pos_scale[, c("id", "Positive scale", "Positive_scale_auto")])

cat("\nРазличия в Negative scale:\n")
print(differences_neg_scale[, c("id", "Negative scale", "Negative_scale_auto")])

cat("\nРазличия в General Psychopathology scale:\n")
print(differences_gen_psychopathology[, c("id", "General Psychopathology scale", "General_Psychopathology_scale_auto")])

cat("\nРазличия в Total score PANSS:\n")
print(differences_total_panss[, c("id", "Total score PANSS", "Total_score_PANSS_auto")])
```

Проверка шкалы BACS.

```{r}
# Код для автоматического расчета Z-баллов. Z-баллы рассчитывались с использованием норматимвных для российской популяции [Саркисян, Г. Р., Гурович, И. Я., & Киф, Р. С. (2010). Нормативные данные для российской популяции и стандартизация шкалы «Краткая оценка когнитивных функций у пациентов с шизофренией» (BACS). Социальная и клиническая психиатрия, 20 (3), 13-19.]

data_compare <- data_filtered %>%
  mutate(
    ZVM_auto = case_when(
      gender == 'м' & age < 30 ~ round((`Verbal Memory` - 49.55) / 7.1, 2),
      gender == 'м' & age > 29 & age < 40 ~ round((`Verbal Memory` - 48.67) / 7.1, 2),
      gender == 'м' & age > 39 & age < 50 ~ round((`Verbal Memory` - 44.44) / 5.47, 2),
      gender == 'ж' & age < 30 ~ round((`Verbal Memory` - 50.52) / 7.94, 2),
      gender == 'ж' & age > 29 & age < 40 ~ round((`Verbal Memory` - 49.77) / 7.25, 2),
      gender == 'ж' & age > 39 & age < 50 ~ round((`Verbal Memory` - 47.00) / 6.35, 2),
      gender == 'ж' & age > 49 & age < 60 ~ round((`Verbal Memory` - 44.33) / 7.32, 2),
      TRUE ~ NA_real_
    ),
    ZDS_auto = case_when(
      gender == 'м' & age < 30 ~ round((`Digit Sequencing` - 21.8) / 2.57, 2),
      gender == 'м' & age > 29 & age < 40 ~ round((`Digit Sequencing` - 22.14) / 3.35, 2),
      gender == 'м' & age > 39 & age < 50 ~ round((`Digit Sequencing` - 20.07) / 3.33, 2),
      gender == 'ж' & age < 30 ~ round((`Digit Sequencing` - 20.24) / 3.50, 2),
      gender == 'ж' & age > 29 & age < 40 ~ round((`Digit Sequencing` - 21.59) / 3.14, 2),
      gender == 'ж' & age > 39 & age < 50 ~ round((`Digit Sequencing` - 20.60) / 3.56, 2),
      gender == 'ж' & age > 49 & age < 60 ~ round((`Digit Sequencing` - 17.90) / 3.69, 2),
      TRUE ~ NA_real_
    ),
    ZMT_auto = case_when(
      gender == 'м' & age < 30 ~ round((`Token Motor Task` - 74.7) / 8.8, 2),
      gender == 'м' & age > 29 & age < 40 ~ round((`Token Motor Task` - 71.43) / 12.15, 2),
      gender == 'м' & age > 39 & age < 50 ~ round((`Token Motor Task` - 74.30) / 11.58, 2),
      gender == 'ж' & age < 30 ~ round((`Token Motor Task` - 68.57) / 9.36, 2),
      gender == 'ж' & age > 29 & age < 40 ~ round((`Token Motor Task` - 72.18) / 8.86, 2),
      gender == 'ж' & age > 39 & age < 50 ~ round((`Token Motor Task` - 71.6) / 12.64, 2),
      gender == 'ж' & age > 49 & age < 60 ~ round((`Token Motor Task` - 68.86) / 11.65, 2),
      TRUE ~ NA_real_
    ),
    ZVF_auto = case_when(
      gender == 'м' & age < 30 ~ round((`Verbal Fluency` - 58.4) / 9.46, 2),
      gender == 'м' & age > 29 & age < 40 ~ round((`Verbal Fluency` - 56.48) / 14.04, 2),
      gender == 'м' & age > 39 & age < 50 ~ round((`Verbal Fluency` - 62.00) / 16.76, 2),
      gender == 'ж' & age < 30 ~ round((`Verbal Fluency` - 54.8) / 14.53, 2),
      gender == 'ж' & age > 29 & age < 40 ~ round((`Verbal Fluency` - 60.45) / 11.05, 2),
      gender == 'ж' & age > 39 & age < 50 ~ round((`Verbal Fluency` - 58.2) / 10.7, 2),
      gender == 'ж' & age > 49 & age < 60 ~ round((`Verbal Fluency` - 58.29) / 10.79, 2),
      TRUE ~ NA_real_
    ),
    ZSC_auto = case_when(
      gender == 'м' & age < 30 ~ round((`Symbol Coding` - 61.95) / 8.06, 2),
      gender == 'м' & age > 29 & age < 40 ~ round((`Symbol Coding` - 61.24) / 10.73, 2),
      gender == 'м' & age > 39 & age < 50 ~ round((`Symbol Coding` - 54.35) / 6.61, 2),
      gender == 'ж' & age < 30 ~ round((`Symbol Coding` - 65.71) / 6.09, 2),
      gender == 'ж' & age > 29 & age < 40 ~ round((`Symbol Coding` - 60.86) / 8.74, 2),
      gender == 'ж' & age > 39 & age < 50 ~ round((`Symbol Coding` - 57.4) / 7.55, 2),
      gender == 'ж' & age > 49 & age < 60 ~ round((`Symbol Coding` - 50.1) / 10.24, 2),
      TRUE ~ NA_real_
    ),
    ZToL_auto = case_when(
      gender == 'м' & age < 30 ~ round((`Tower of London` - 18.45) / 1.82, 2),
      gender == 'м' & age > 29 & age < 40 ~ round((`Tower of London` - 19.1) / 1.67, 2),
      gender == 'м' & age > 39 & age < 50 ~ round((`Tower of London` - 18.35) / 2.98, 2),
      gender == 'ж' & age < 30 ~ round((`Tower of London` - 17.67) / 1.93, 2),
      gender == 'ж' & age > 29 & age < 40 ~ round((`Tower of London` - 17.64) / 1.71, 2),
      gender == 'ж' & age > 39 & age < 50 ~ round((`Tower of London` - 17.4) / 1.76, 2),
      gender == 'ж' & age > 49 & age < 60 ~ round((`Tower of London` - 16.48) / 2.36, 2),
      TRUE ~ NA_real_
    )
  )

data_compare <- data_compare %>% mutate(
  Comp_Z_auto = round(rowSums(select(., ZVM_auto:ZToL_auto))/ 3.96, 2))
```

```{r}
# Сравниваем
differences_ZVM <- data_compare %>%
  filter(ZVM_auto != ZVM)

differences_ZDS <- data_compare %>%
  filter(ZDS_auto != ZDS)

differences_ZMT <- data_compare %>%
  filter(ZMT_auto != ZMT)

differences_ZVF <- data_compare %>%
  filter(ZVF_auto != ZVF)

differences_ZSC <- data_compare %>%
  filter(ZSC_auto != ZSC)

differences_ZToL <- data_compare %>%
  filter(ZToL_auto != ZToL)

differences_Comp_Z <- data_compare %>%
  filter(Comp_Z_auto != `Comp Z`)
```

```{r echo=FALSE}
# Выводим результаты
cat("Различия в ZVM:\n")
print(differences_ZVM[, c("id", "ZVM", "ZVM_auto")])

cat("\nРазличия в ZDS:\n")
print(differences_ZDS[, c("id", "ZDS", "ZDS_auto")])

cat("\nРазличия в ZMT:\n")
print(differences_ZMT[, c("id", "ZMT", "ZMT_auto")])

cat("\nРазличия в ZVF:\n")
print(differences_ZVF[, c("id", "ZVF", "ZVF_auto")])

cat("Различия в ZSC:\n")
print(differences_ZSC[, c("id", "ZSC", "ZSC_auto")])

cat("Различия в ZToL:\n")
print(differences_ZToL[, c("id", "ZToL", "ZToL_auto")])

cat("Различия в Comp Z:\n")
print(differences_Comp_Z[, c("id", "Comp Z", "Comp_Z_auto")])
```


Выявлены ошибки в Total score SAS, Positive scale, Negative scale, General Psychopathology scale, Total score PANSS.
Так же выявлены ошибки во всех BACS.


## Исправление ошибок
Для замены данных правильными, создан скрипт preprocessing.R: 

- Исправиляет найденные ошибки в шкалах.

- Добавляет 5-факторную модель.

- Добавляет хлорпромазиновый эквивалент.

- Создает Data_SAS_fixed.xlsx в _misc.

```{r}
path <- here("scripts/0_preprocessing", "preprocessing.R")
source(path)
path <- here("data", "Data_SAS.xlsx")
data_filtered <- preprocessing(path)
```

## EDA - исправленные данные

```{r}
# data_filtered %>%
# glimpse()
# data_filtered %>% colnames()
```

```{r}
data_filtered %>% 
  select("gender", "age", "disease duration", "antipsychotic dose", "antipsychotic generation", "THF dose", "course", "education", "smoke", "Total score SAS", "Total score PANSS", "Comp Z", "CPZE") %>% 
  describe() %>% 
  select(vars, n, mean, sd, median, min, max, range) %>% 
  kable("html") %>%
  kable_styling("striped", full_width = FALSE)
```


```{r}
data_filtered %>% 
  select("gender", "age", "disease duration", "antipsychotic dose", "antipsychotic generation", "THF dose", "course", "education", "smoke", "visit", "Total score SAS", "Total score PANSS", "Comp Z", "CPZE") %>% 
  summary() %>% 
  kable("html") %>%
  kable_styling("striped", full_width = FALSE)
```

## EDA с помощью Shiny

```{r eval=FALSE}
path <- here("scripts/1_eda", "eda_shiny_func.R")
source(path)
eda_shiny(data_filtered)

#eda_shiny(divide_by_treat_resp)

```


# Динамика

Исследуем изменение количественных переменных между визитами используя:

- Тест Шапиро-Уилка для определение нормальности распределения. Укажем в normality_result.

- t-тест для зависимых выборок (paired=TRUE, $\alpha = 0.05$). Укажем значимость в t_significant_flag. 

- тест Уилкоксона для парных данных ($\alpha = 0.05$). Укажем значимость в wilcoxon_significant_flag 

```{r}
# Указываем переменные, для которых хотим провести t-тест
selected_variables <- data_filtered %>% select_if(is.numeric) %>% names()

# Проводим t-тест и тест на нормальность для каждой переменной
alpha = 0.05  # Устанавливаем уровень значимости
test_results <- lapply(selected_variables, function(variable) {
  # Проводим тест на нормальность
  normality_test_result <- shapiro.test(data_filtered[[variable]])
  
  # Проводим t-тест независимо от результата теста на нормальность
  visit_1 <- data_filtered %>% 
    filter(visit == 1) %>% 
    pull(variable)
  visit_2 <- data_filtered %>% 
    filter(visit == 2) %>% 
    pull(variable)
  test_result <- t.test(visit_1, visit_2, paired=TRUE)
  
  # Собираем результаты в data frame
  result_df <- data.frame(
    Variable = variable,
    t_value = test_result$statistic,
    t_p_value = test_result$p.value,
    t_significant_flag = ifelse(test_result$p.value < alpha, "1", "0"),
    normality_p_value = normality_test_result$p.value,
    normality_result = ifelse(normality_test_result$p.value > 0.05, "Normal", "Not normal")
  )
  return(result_df)
})

# Объединяем результаты
test_results <- bind_rows(test_results)

# Добавляем тест Уилкоксона к результатам
wilcoxon_test_result <- lapply(selected_variables, function(variable) {
  wilcoxon_result <- wilcox.test(data_filtered[[variable]] ~ data_filtered$visit)
  result_df <- data.frame(
    Variable = variable,
    wilcoxon_statistic = wilcoxon_result$statistic,
    wilcoxon_p_value = wilcoxon_result$p.value,
    wilcoxon_significant_flag = ifelse(wilcoxon_result$p.value < alpha, "1", "0")
  )
  return(result_df)
})

# Объединяем результаты Уилкоксона с предыдущими результатами
wilcoxon_test_result <- bind_rows(wilcoxon_test_result)
test_results <- left_join(test_results, wilcoxon_test_result, by = "Variable")

# Выводим результаты
test_results %>% 
  kable(format = "html") %>%
  kable_styling("striped", full_width = FALSE)
```


Только значимые:

```{r}
significant_variables <- test_results %>% 
  filter(t_significant_flag == 1 | wilcoxon_significant_flag == 1)
significant_variables %>% 
  select(Variable, t_significant_flag, wilcoxon_significant_flag, normality_result) %>% 
  kable(format = "html") %>%
  kable_styling("striped", full_width = FALSE)
```

Создадим датафрейм, содержащие разницу количественных показателей между визитами.
Для этого используем make_difference_df.R

```{r}
path <- here("scripts/0_preprocessing", "make_difference_df.R")
source(path)
difference_df <- make_dif_df(data_filtered)
difference_df
```
 Визуализируем: 
 
```{r}
difference_df %>%
  gather(variable, value, -id) %>%
  group_by(variable) %>%
  summarise(mean_value = mean(value, na.rm = TRUE)) %>%
  filter(grepl("_dif$", variable)) %>%
  mutate(variable = gsub("_dif$", "", variable)) %>%
  ggplot(aes(x = variable, y = mean_value)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  labs(title = "Средние отклонение переменных",
       x = "Переменные",
       y = "Среднее отклонение") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

Тоже самое более кратко.

```{r}
difference_df %>%
  gather(variable, value, -id) %>%
  filter(!grepl("G[1-9]|N[1-7]|P[1-7]_dif$", variable)) %>%
  group_by(variable) %>%
  summarise(mean_value = mean(value, na.rm = TRUE)) %>%
  filter(grepl("_dif$", variable)) %>%
  mutate(variable = gsub("_dif$", "", variable)) %>%
  ggplot(aes(x = variable, y = mean_value, fill = factor(sign(mean_value)))) +
  geom_bar(stat = "identity", color = "black") +
  scale_fill_manual(values = c("blue", "gray", "red"), name = "Знак", labels = c("Отрицательное", "Ноль", "Положительное")) +
  labs(title = "Средние отклонение переменных",
       x = "Переменные",
       y = "Среднее отклонение") +
  theme_minimal() +
  guides(fill = FALSE) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

EDA difference_df в shiny доступна только для числовых переменнных.

Доступна только вкладка "Числовые переменные" без разбития по visit.

```{r eval=FALSE}
path <- here("scripts/1_eda", "eda_shiny_func.R")
source(path)
eda_shiny(difference_df)
```

## Строим модель

### Первые модели для Comp_Z_dif

Простая модель, включающая только `Total score SAS_dif`, `Total score PANSS_dif`. Предсказываем  `Comp Z_dif`

```{r}
lm(`Comp Z_dif` ~ `Total score SAS_dif` + `Total score PANSS_dif`, data=difference_df) %>% 
  summary()
```

Модель получается лучше, если оставить только `Total score SAS_dif`

```{r}
lm(`Comp Z_dif` ~ `Total score SAS_dif`, data=difference_df) %>% 
  summary()
```

Теперь попробуем построить сложную модель, пусть функция step разбирается. Установим trace=0, чтобы увидеть только последнюю модель.

```{r}
# уберем линейно зависимые переменные
selected_data <- difference_df %>% 
  select(-id, -excitment_dif, -cognitive_dif, -depression_dif , 
         -starts_with('N'), -starts_with('P'), -starts_with('G'), -starts_with('Z'))
lm(`Comp Z_dif` ~ ., data=selected_data) %>% 
  step(trace=0) %>%
  summary()
```

### Модель для Comp Z_dif

Исключим так же `Verbal Memory`, `Digit Sequencing`, `Token Motor Task`, `Verbal Fluency`, `Symbol Coding`, `Tower of London`.

```{r}
selected_data <- difference_df %>% 
  select(-id, -excitment_dif, -cognitive_dif, -depression_dif , 
         -starts_with('N'), -starts_with('P'), -starts_with('G'), -starts_with('Z')) %>% 
  select(-`Verbal Memory_dif`, -`Digit Sequencing_dif`, 
         -`Token Motor Task_dif`, -`Verbal Fluency_dif`, -`Symbol Coding_dif`, -`Tower of London_dif`)

lm(`Comp Z_dif` ~ ., data=selected_data) %>% 
  step(trace=0) %>% 
  summary()
```
Модель объясняет примерно 26 % дисперсии (Multiple R-squared:  0.264,	Adjusted R-squared:  0.1873).

### 5-факторная модель PANSS для Comp Z_dif

Теперь используем 5-факторную модель PANSS 
```{r}
selected_data <- difference_df %>% 
  select(-id, -starts_with(c("N", "P", "G", "Z")), negative_dif, positive_dif, CPZE) %>% 
  select(-`Verbal Memory_dif`, -`Digit Sequencing_dif`, -`Token Motor Task_dif`, 
         -`Verbal Fluency_dif`, -`Symbol Coding_dif`, -`Tower of London_dif`)

lm(`Comp Z_dif` ~ ., data = selected_data) %>% 
  step(trace=0) %>% 
  summary()
```
Модель объясняет примерно 41.49% дисперсии (Multiple R-squared:  0.4149,	Adjusted R-squared:  0.3109).

Эта же модель с подробным описанием.
```{r}
model <- lm(`Comp Z_dif` ~ `shoulder shaking_dif` + `elbow rigidity_dif` + `wrist rigidity_dif` + salivation_dif +
     `Total score SAS_dif` + `Total score PANSS_dif` + cognitive_dif + depression_dif, data=selected_data)
tidy_results <- tidy(model)
glance_results <- glance(model) %>% 
  select(r.squared, adj.r.squared, sigma, logLik, AIC, BIC, df.residual, nobs)
results <- bind_cols(tidy_results, glance_results)
results %>%
  kable("html") %>%
  kable_styling("striped", full_width = FALSE)
```

Здесь можно поразвлекаться с моделями.
```{r}
lm(`Comp Z_dif` ~ `shoulder shaking_dif` + `elbow rigidity_dif` + `wrist rigidity_dif` +
    salivation_dif + `Total score SAS_dif` + `Total score PANSS_dif` + cognitive_dif + 
    depression_dif, data=selected_data) %>% 
  summary()
```
### Другая модель (ZVM_dif, ZSC_dif, ZVF_dif, ZDS_dif, ZToL_dif, ZMT_dif)

Исключим так же `Comp Z_dif`, но добавим ZVM_dif, ZSC_dif, ZVF_dif, ZDS_dif, ZToL_dif, ZMT_dif.
Будем строить модели для предсказания отдельных показателей когнитивных функций по разнице между визитами.

Создаем датафреймы.

```{r}
# Для предсказания ZVM_dif
selected_data_ZVM_dif <- difference_df %>% 
  select(-id, -excitment_dif, -cognitive_dif, -depression_dif , 
         -starts_with('N'), -starts_with('P'), -starts_with('G'), -starts_with('Z'), ZVM_dif, gait_dif, `glabella tap_dif`) %>% 
  select(-`Verbal Memory_dif`, -`Digit Sequencing_dif`, 
         -`Token Motor Task_dif`, -`Verbal Fluency_dif`, -`Symbol Coding_dif`, -`Tower of London_dif`) %>% 
  select(-`Comp Z_dif`)

# Для предсказания ZSC_dif
selected_data_ZSC_dif <- difference_df %>% 
  select(-id, -excitment_dif, -cognitive_dif, -depression_dif , 
         -starts_with('N'), -starts_with('P'), -starts_with('G'), -starts_with('Z'), ZSC_dif, gait_dif, `glabella tap_dif`) %>% 
  select(-`Verbal Memory_dif`, -`Digit Sequencing_dif`, 
         -`Token Motor Task_dif`, -`Verbal Fluency_dif`, -`Symbol Coding_dif`, -`Tower of London_dif`) %>% 
  select(-`Comp Z_dif`)

# Для предсказания ZVF_dif
selected_data_ZVF_dif <- difference_df %>% 
  select(-id, -excitment_dif, -cognitive_dif, -depression_dif , 
         -starts_with('N'), -starts_with('P'), -starts_with('G'), -starts_with('Z'), ZVF_dif, gait_dif, `glabella tap_dif`) %>% 
  select(-`Verbal Memory_dif`, -`Digit Sequencing_dif`, 
         -`Token Motor Task_dif`, -`Verbal Fluency_dif`, -`Symbol Coding_dif`, -`Tower of London_dif`) %>% 
  select(-`Comp Z_dif`)

# Для предсказания ZDS_dif
selected_data_ZDS_dif <- difference_df %>% 
  select(-id, -excitment_dif, -cognitive_dif, -depression_dif , 
         -starts_with('N'), -starts_with('P'), -starts_with('G'), -starts_with('Z'), ZDS_dif, gait_dif, `glabella tap_dif`) %>% 
  select(-`Verbal Memory_dif`, -`Digit Sequencing_dif`, 
         -`Token Motor Task_dif`, -`Verbal Fluency_dif`, -`Symbol Coding_dif`, -`Tower of London_dif`) %>% 
  select(-`Comp Z_dif`)

# Для предсказания ZToL_dif
selected_data_ZToL_dif <- difference_df %>% 
  select(-id, -excitment_dif, -cognitive_dif, -depression_dif , 
         -starts_with('N'), -starts_with('P'), -starts_with('G'), -starts_with('Z'), ZToL_dif, gait_dif, `glabella tap_dif`) %>% 
  select(-`Verbal Memory_dif`, -`Digit Sequencing_dif`, 
         -`Token Motor Task_dif`, -`Verbal Fluency_dif`, -`Symbol Coding_dif`, -`Tower of London_dif`) %>% 
  select(-`Comp Z_dif`)

# Для предсказания ZMT_dif
selected_data_ZMT_dif <- difference_df %>% 
  select(-id, -excitment_dif, -cognitive_dif, -depression_dif , 
         -starts_with('N'), -starts_with('P'), -starts_with('G'), -starts_with('Z'), ZMT_dif, gait_dif, `glabella tap_dif`) %>% 
  select(-`Verbal Memory_dif`, -`Digit Sequencing_dif`, 
         -`Token Motor Task_dif`, -`Verbal Fluency_dif`, -`Symbol Coding_dif`, -`Tower of London_dif`) %>% 
  select(-`Comp Z_dif`)

# Для предсказания Comp Z_dif
selected_data_Comp_Z_dif <- difference_df %>% 
  select(-id, -excitment_dif, -cognitive_dif, -depression_dif , 
         -starts_with('N'), -starts_with('P'), -starts_with('G'), -starts_with('Z'), gait_dif, `glabella tap_dif`) %>% 
  select(-`Verbal Memory_dif`, -`Digit Sequencing_dif`, 
         -`Token Motor Task_dif`, -`Verbal Fluency_dif`, -`Symbol Coding_dif`, -`Tower of London_dif`)

```

Проверим, правильно ли выбрали

```{r}
# Сравнение числа колонок
num_cols_ZVM_dif <- ncol(selected_data_ZVM_dif)
num_cols_ZSC_dif <- ncol(selected_data_ZSC_dif)
num_cols_ZVF_dif <- ncol(selected_data_ZVF_dif)
num_cols_ZDS_dif <- ncol(selected_data_ZDS_dif)
num_cols_ZToL_dif <- ncol(selected_data_ZToL_dif)
num_cols_ZMT_dif <- ncol(selected_data_ZMT_dif)
num_cols_Comp_Z_dif <- ncol(selected_data_Comp_Z_dif)

# Печать результатов
cat("Число колонок в selected_data_ZVM_dif:", num_cols_ZVM_dif, "\n")
cat("Число колонок в selected_data_ZSC_dif:", num_cols_ZSC_dif, "\n")
cat("Число колонок в selected_data_ZVF_dif:", num_cols_ZVF_dif, "\n")
cat("Число колонок в selected_data_ZDS_dif:", num_cols_ZDS_dif, "\n")
cat("Число колонок в selected_data_ZToL_dif:", num_cols_ZToL_dif, "\n")
cat("Число колонок в selected_data_ZMT_dif:", num_cols_ZMT_dif, "\n")
cat("Число колонок в selected_data_Comp_Z_dif:", num_cols_Comp_Z_dif, "\n")
```
Построение моделей.
```{r}
fit_ZVM_dif <- lm(ZVM_dif ~ ., data=selected_data_ZVM_dif) %>% 
  step(trace=0)
fit_ZSC_dif <- lm(ZSC_dif ~ ., data=selected_data_ZSC_dif) %>% 
  step(trace=0) 
fit_ZVF_dif <- lm(ZVF_dif ~ ., data=selected_data_ZVF_dif) %>% 
  step(trace=0)
fit_ZDS_dif <- lm(ZDS_dif ~ ., data=selected_data_ZDS_dif) %>% 
  step(trace=0)
fit_ZTOL_dif <- lm(ZToL_dif ~ ., data=selected_data_ZToL_dif) %>% 
  step(trace=0)
fit_ZMT_dif <- lm(ZMT_dif ~ ., data=selected_data_ZMT_dif) %>% 
  step(trace=0)


#fit_ZVM_dif %>% summary()
#fit_ZSC_dif %>% summary()
#fit_ZVF_dif %>% summary()
#fit_ZDS_dif %>% summary()
#fit_ZTOL_dif %>% summary()
#fit_ZMT_dif %>% summary()
```

Посмотрим что получилось
```{r}
# Функция для измлечения p-value модели
overall_p <- function(my_model) {
    f <- summary(my_model)$fstatistic
    p <- pf(f[1],f[2],f[3],lower.tail=F)
    attributes(p) <- NULL
    return(p)
}

# Создание списка моделей с явными именами
model_list <- list(
  ZVM = fit_ZVM_dif,
  ZSC = fit_ZSC_dif,
  ZVF = fit_ZVF_dif,
  ZDS = fit_ZDS_dif,
  ZTOL = fit_ZTOL_dif,
  ZMT = fit_ZMT_dif
)

# Извлечение статистики из каждой модели
model_stats <- lapply(model_list, function(model) {
  r_squared <- summary(model)$r.squared
  adj_r_squared <- summary(model)$adj.r.squared
  f_statistic <- summary(model)$fstatistic
  p_value <- overall_p(model)
  
  data.frame(
    R_squared = r_squared,
    Adj_R_squared = adj_r_squared,
    F_statistic = f_statistic[1],
    p_value = p_value
  )
})

# Объединение результатов в один датафрейм
model_summary_table <- do.call(rbind, model_stats)

# Вывод сводной таблицы
model_summary_table %>% 
  arrange(-Adj_R_squared, p_value)
```
ZMT, ZTOL, ZSC, ZVF - хорошо, 

ZDS, ZVM - плохо

### Модели Comp_Z по отдельным визитам

visit = 1

```{r}
selected_data <- data_filtered %>%
  filter(visit == 1) %>% 
  select(-id, -visit) %>% 
  select(-excitment, -cognitive, -depression, 
         -starts_with('N'), -starts_with('P'), -starts_with('G'), -starts_with('Z'), gender, gait) %>% 
  select(-`Verbal Memory`, -`Digit Sequencing`, 
         -`Token Motor Task`, -`Verbal Fluency`, -`Symbol Coding`, -`Tower of London`)
  
lm(`Comp Z` ~ ., data=selected_data) %>% 
  step(trace=0) %>% summary()
```
Multiple R-squared:  0.9161,	Adjusted R-squared:  0.5554

visit = 2

```{r}
selected_data <- data_filtered %>%
  filter(visit == 2) %>% 
  select(-id, -visit) %>% 
  select(-excitment, -cognitive, -depression, 
         -starts_with('N'), -starts_with('P'), -starts_with('G'), -starts_with('Z'), gender, gait) %>% 
  select(-`Verbal Memory`, -`Digit Sequencing`, 
         -`Token Motor Task`, -`Verbal Fluency`, -`Symbol Coding`, -`Tower of London`)
  
lm(`Comp Z` ~ ., data=selected_data) %>% 
  step(trace=0) %>% summary()
```
Multiple R-squared:  0.9299,	Adjusted R-squared:  0.4692 

### Разбиваем на группы по ответу на терапию

```{r}
divide_by_treat_resp <- data_filtered %>%
  filter(visit %in% c('1', '2')) %>%
  group_by(id) %>%
  mutate(
    percentage_change = ((as.numeric(`Total score PANSS`[visit == '1']) - as.numeric(`Total score PANSS`[visit == '2'])) / as.numeric(`Total score PANSS`[visit == '1'])) * 100
  ) %>% 
  ungroup()

divide_by_treat_resp <- divide_by_treat_resp %>% 
  mutate(
  treat_resp = case_when(
    percentage_change < 15 ~ 0, # неответившие на терапию
    percentage_change >= 15 & percentage_change <= 20 ~ 1, # с недостаточным ответом
    percentage_change > 20 ~ 2, # ответившие на терапию
    TRUE ~ NA_real_
  )
)
divide_by_treat_resp %>% 
  ggplot() + 
  aes(treat_resp) +
  geom_histogram(binwidth = 1) +
  theme_minimal()
```
### Модели с добавлением ответа на терапию

Без разбития на визиты

```{r}
selected_data <- divide_by_treat_resp %>%
  select(-id) %>% 
  select(-excitment, -cognitive, -depression, 
         -starts_with('N'), -starts_with('P'), -starts_with('G'), -starts_with('Z'), gender, gait) %>% 
  select(-`Verbal Memory`, -`Digit Sequencing`, 
         -`Token Motor Task`, -`Verbal Fluency`, -`Symbol Coding`, -`Tower of London`)

lm(`Comp Z` ~ ., data=selected_data) %>% 
  step(trace=0) %>% summary()
```

Multiple R-squared:  0.8284,	Adjusted R-squared:  0.7039

visit = 1 

```{r}
selected_data <- divide_by_treat_resp %>%
  filter(visit == 1) %>% 
  select(-id, -visit) %>% 
  select(-excitment, -cognitive, -depression, 
         -starts_with('N'), -starts_with('P'), -starts_with('G'), -starts_with('Z'), gender, gait) %>% 
  select(-`Verbal Memory`, -`Digit Sequencing`, 
         -`Token Motor Task`, -`Verbal Fluency`, -`Symbol Coding`, -`Tower of London`)
  
lm(`Comp Z` ~ ., data=selected_data) %>% 
  step(trace=0) %>% summary()
```
Multiple R-squared:  0.8867,	Adjusted R-squared:  0.1422

visit = 2

```{r}
selected_data <- divide_by_treat_resp %>%
  filter(visit == 2) %>% 
  select(-id, -visit) %>% 
  select(-excitment, -cognitive, -depression, 
         -starts_with('N'), -starts_with('P'), -starts_with('G'), -starts_with('Z'), gender, gait) %>% 
  select(-`Verbal Memory`, -`Digit Sequencing`, 
         -`Token Motor Task`, -`Verbal Fluency`, -`Symbol Coding`, -`Tower of London`)
  
sum <- lm(`Comp Z` ~ ., data=selected_data) %>% 
  step(trace=0) %>% summary()
```

Multiple R-squared:  0.9186,	Adjusted R-squared:  0.608 


### lm с помощью Shiny можно запустить.

Для обоих визитов:

```{r eval=FALSE}
path <- here("scripts/1_eda", "lm_shiny.R")
source(path)
lm_shiny(data_filtered %>% select(!matches("P\\d{1}") & !matches("N\\d{1}") & !matches("G\\d{1}") & !id))
```


Для разницы между визитами:

```{r eval=FALSE}
path <- here("scripts/1_eda", "lm_shiny.R")
source(path)
lm_shiny(difference_df %>% select(!matches("P\\d{1}") & !matches("N\\d{1}") & !matches("G\\d{1}") & !id))
```
### Смешанные модели

Испульзуя корреляционный анализ, решили строить смешанные модели, для предсказания когнитивных функций 

- ZVM

- ZMT

- ZVF

- ZToL

- Comp Z


Создадим датафреймы:


```{r}
# Создание датафреймов (если они еще не созданы)
selected_data_ZVM <- data_filtered %>% 
  select(-excitment, -cognitive, -depression , 
         -starts_with('N'), -starts_with('P'), -starts_with('G'), -starts_with('Z'), ZVM, gender, gait, `glabella tap`) %>% 
  select(-`Verbal Memory`, -`Digit Sequencing`, 
         -`Token Motor Task`, -`Verbal Fluency`, -`Symbol Coding`, -`Tower of London`) %>% 
  select(-`Comp Z`)

selected_data_ZMT <- data_filtered %>% 
  select(-excitment, -cognitive, -depression, 
         -starts_with('N'), -starts_with('P'), -starts_with('G'), -starts_with('Z'), ZMT, gender, gait, `glabella tap`) %>% 
  select(-`Verbal Memory`, -`Digit Sequencing`, 
         -`Token Motor Task`, -`Verbal Fluency`, -`Symbol Coding`, -`Tower of London`) %>% 
  select(-`Comp Z`)

selected_data_ZVF <- data_filtered %>% 
  select(-excitment, -cognitive, -depression, 
         -starts_with('N'), -starts_with('P'), -starts_with('G'), -starts_with('Z'), ZVF, gender, gait, `glabella tap`) %>% 
  select(-`Verbal Memory`, -`Digit Sequencing`, 
         -`Token Motor Task`, -`Verbal Fluency`, -`Symbol Coding`, -`Tower of London`) %>% 
  select(-`Comp Z`)

selected_data_ZToL <- data_filtered %>% 
  select(-excitment, -cognitive, -depression, 
         -starts_with('N'), -starts_with('P'), -starts_with('G'), -starts_with('Z'), ZToL, gender, gait, `glabella tap`) %>% 
  select(-`Verbal Memory`, -`Digit Sequencing`, 
         -`Token Motor Task`, -`Verbal Fluency`, -`Symbol Coding`, -`Tower of London`) %>% 
  select(-`Comp Z`)

selected_data_Comp_Z <- data_filtered %>% 
  select(-excitment, -cognitive, -depression, 
         -starts_with('N'), -starts_with('P'), -starts_with('G'), -starts_with('Z'), `Comp Z`, gender, gait, `glabella tap`) %>% 
  select(-`Verbal Memory`, -`Digit Sequencing`, 
         -`Token Motor Task`, -`Verbal Fluency`, -`Symbol Coding`, -`Tower of London`)

# Сравнение числа колонок
num_cols_ZVM <- ncol(selected_data_ZVM)
num_cols_ZMT <- ncol(selected_data_ZMT)
num_cols_ZVF <- ncol(selected_data_ZVF)
num_cols_ZToL <- ncol(selected_data_ZToL)
num_cols_Comp_Z <- ncol(selected_data_Comp_Z)

# Печать результатов
cat("Число колонок в selected_data_ZVM:", num_cols_ZVM, "\n")
cat("Число колонок в selected_data_ZMT:", num_cols_ZMT, "\n")
cat("Число колонок в selected_data_ZVF:", num_cols_ZVF, "\n")
cat("Число колонок в selected_data_ZToL:", num_cols_ZToL, "\n")
cat("Число колонок в selected_data_Comp_Z:", num_cols_Comp_Z, "\n")

```
#### Первая попытка.
Смешанная модель, в качестве случайного эффекта выбран id пациента.
Используем lmer из пакета lmerTest, чтобы оценить p-value.

```{r}
lm(ZVM ~ `Total score SAS`, data = selected_data_ZVM %>% 
  filter(visit==1)) %>% 
  summary()
```


```{r}
mixed_model <- lmer(ZVM ~ `Total score SAS` + (1 | id), data = selected_data_ZVM, REML=F)
summary(mixed_model)
```

#### Для оценки фиксированного и случайного эффекта можно использовать:

```{r}
#fixef(mixed_model)
#ranef(mixed_model)
```


Теперь построим и сравним модели
```{r}
# Создание смешанных линейных моделей для различных зависимых переменных
mixed_model_ZVM <- lmer(ZVM ~ `Total score SAS` + (1 | id), data = selected_data_ZVM, REML = FALSE)
mixed_model_ZMT <- lmer(ZMT ~ `Total score SAS` + (1 | id), data = selected_data_ZMT, REML = FALSE)
mixed_model_ZVF <- lmer(ZVF ~ `Total score SAS` + (1 | id), data = selected_data_ZVF, REML = FALSE)
mixed_model_ZToL <- lmer(ZToL ~ `Total score SAS` + (1 | id), data = selected_data_ZToL, REML = FALSE)
mixed_model_Comp_Z <- lmer(`Comp Z` ~ `Total score SAS` + (1 | id), data = selected_data_Comp_Z, REML = FALSE)

# Создание списка моделей
model_list <- list(
  mixed_model_ZVM = mixed_model_ZVM,
  mixed_model_ZMT = mixed_model_ZMT,
  mixed_model_ZVF = mixed_model_ZVF,
  mixed_model_ZToL = mixed_model_ZToL,
  mixed_model_Comp_Z = mixed_model_Comp_Z
)

# Извлечение информации о критериях для каждой модели
model_summary <- lapply(names(model_list), function(model_name) {
  model <- model_list[[model_name]]
  data.frame(
    Model = model_name,
    AIC = AIC(model),
    BIC = BIC(model),
    logLik = logLik(model),
    deviance = deviance(model),
    df.resid = df.residual(model)
  )
})

# Создание сводного датафрейма
summary_dataframe <- do.call(rbind, model_summary)

# Вывод сводного датафрейма
summary_dataframe %>% 
  arrange(AIC)
```
Самые лучшая модель по mixed_model_ZVF.

#### Следующий этап. Строим много моделей.

Строим модели:

1.1.1 ZVM ~ `Total score PANSS` + `THF dose`

1.1.2 ZVM ~ as.factor(`head rotation`) + `Total score PANSS` + `THF dose`

1.2.1 ZMT ~ `Total score PANSS` + `THF dose`

1.2.2 ZMT ~ as.factor(akathisia) + `Total score PANSS` + `THF dose`

1.3. ZMT ~ `Total score SAS` + `Total score PANSS` + `THF dose`

1.4.1 ZVF ~ as.factor(tremor) + `Total score PANSS` + `THF dose`

1.4.2 ZVF ~ `Total score PANSS` + `THF dose`

1.5 ZToL ~ `Total score SAS` + `Total score PANSS` + `THF dose`

```{r}
model_1_1_1 <- lm(ZVM ~ `Total score PANSS` + `THF dose`, data = selected_data_ZVM)
model_1_1_2 <- lm(ZVM ~ as.factor(`head rotation`) + `Total score PANSS` + `THF dose`, data = selected_data_ZVM)

model_1_2_1 <- lm(ZMT ~ `Total score PANSS` + `THF dose`, data = selected_data_ZMT)
model_1_2_2 <- lm(ZMT ~ as.factor(akathisia) + `Total score PANSS` + `THF dose`, data = selected_data_ZMT)

model_1_3 <- lm(ZMT ~ `Total score SAS` + `Total score PANSS` + `THF dose`, data = selected_data_ZMT)

model_1_4_1 <- lm(ZVF ~ `Total score PANSS` + `THF dose`, data = selected_data_ZVF)

model_1_4_2 <- lm(ZVF ~ as.factor(tremor) + `Total score PANSS` + `THF dose`, data = selected_data_ZVF)

model_1_5 <- lm(ZToL ~ `Total score SAS` + `Total score PANSS` + `THF dose`, data = selected_data_ZToL) 
```

Попарно сравниваем и берем p-value

- model_1_1_1 и model_1_1_2

- model_1_2_1 и model_1_2_2

- model_1_4_1 и model_1_4_2

Для моделей model_1_3 и model_1_5 берем p-value для `Total score SAS`
Применим поправку Бенджамина Хохберга.


```{r}
# Сравнение моделей с использованием anova
anova_result_1 <- anova(model_1_1_1, model_1_1_2)
anova_result_2 <- anova(model_1_2_1, model_1_2_2)
summary_3 <- model_1_3 %>% summary()
anova_result_4 <- anova(model_1_4_1, model_1_4_2)
summary_5 <-model_1_5 %>% summary()
# Получение p-значения из второго элемента массива Pr(>F) для каждого сравнения
p_value_1 <- anova_result_1$`Pr(>F)`[2]
p_value_2 <- anova_result_2$`Pr(>F)`[2]
p_value_3 <- summary_3$coefficients[14]
p_value_4 <- anova_result_4$`Pr(>F)`[2]
p_value_5 <- summary_5$coefficients[14]

# Создание tibble с p-значениями
tibble(
  Model = c("ZVM", "ZMT_1", "ZMT_2", "ZVF", "ZToL"),
  P_Value = round(c(p_value_1, p_value_2, p_value_3, p_value_4, p_value_5), 3), 
  P_Adjusted = round(p.adjust(c(p_value_1, p_value_2, p_value_3, p_value_4, p_value_5), method = "BH"), 3)
)
```

Красиво выводим модели

```{r}
# Загрузка необходимых библиотек
library(dplyr)
library(knitr)

# Создание функции для получения summary и преобразования в таблицу
get_lm_summary_table <- function(model, dependent_variable) {
  summary_data <- summary(model)
  
  # Извлечение интересующих вас данных из summary
  coefficients <- summary_data$coefficients[, c("Estimate", "Std. Error", "t value", "Pr(>|t|)")]
  
  # Создание таблицы
  table_data <- as.data.frame(coefficients)
  table_data$Variable <- rownames(coefficients)
  rownames(table_data) <- NULL
  
  # Добавление имени зависимой переменной
  table_data <- cbind(Dependent_Variable = dependent_variable, table_data)
  
  return(table_data)
}

# Получение таблиц для каждой модели
table_ZVM_1 <- get_lm_summary_table(model_1_1_1, "ZVM_1")
table_ZVM_2 <- get_lm_summary_table(model_1_1_2, "ZVM_2")

table_ZMT_1_1 <- get_lm_summary_table(model_1_2_1, "ZMT_1_1")
table_ZMT_1_2 <- get_lm_summary_table(model_1_2_2, "ZMT_1_2")

table_ZMT_2 <- get_lm_summary_table(model_1_3, "ZMT_2")

table_ZVF_1 <- get_lm_summary_table(model_1_4_1, "ZVF_1")
table_ZVF_2 <- get_lm_summary_table(model_1_4_2, "ZVF_2")

table_ZToL <- get_lm_summary_table(model_1_5, "ZToL")

# Объединение таблиц в одну
final_table <- rbind(table_ZVM_1, table_ZVM_2, table_ZMT_1_1, table_ZMT_1_2, table_ZMT_2, table_ZVF_1, table_ZVF_2, table_ZToL)

# Вывод таблицы
kable(final_table, format = "html")

```


Строим смешанные модели:

- ZVM ~ as.factor(`head rotation`) + `Total score PANSS` + `THF dose` + visit + (1 | id)

- ZMT ~ as.factor(akathisia) + `Total score PANSS` + `THF dose` + visit + (1 | id) 

- ZMT ~ `Total score SAS` + `Total score PANSS` + `THF dose` + visit + (1 | id)

- ZVF ~ tremor + `Total score PANSS` + `THF dose` + visit + (1 | id)

- ZToL ~ `Total score SAS` + `Total score PANSS` + `THF dose` + visit + (1 | id)


```{r}
lmer(ZVM ~ as.factor(`head rotation`) + `Total score PANSS` + `THF dose` + visit + (1 | id), data = selected_data_ZVM, REML = FALSE) %>% summary()
lmer(ZMT ~ as.factor(akathisia) + `Total score PANSS` + `THF dose` + visit + (1 | id), data = selected_data_ZMT, REML = FALSE) %>% summary()
lmer(ZMT ~ `Total score SAS` + `Total score PANSS` + `THF dose` + visit + (1 | id), data = selected_data_ZMT, REML = FALSE) %>% summary()
lmer(ZVF ~ tremor + `Total score PANSS` + `THF dose` + visit + (1 | id), data = selected_data_ZVF, REML = FALSE) %>% summary()
lmer(ZToL ~ `Total score SAS` + `Total score PANSS` + `THF dose` + visit + (1 | id), data = selected_data_ZToL, REML = FALSE) %>% summary()
```

#### Модели для вклада ЭПС терапии и симптомов шизофрении

`head rotation` ~ CPZE

tremor ~ CPZE + depression

akathisia ~ CPZE + `Total score PANSS`

`Total score SAS` ~ CPZE + `Total score PANSS`

```{r}
lm(`head rotation` ~ CPZE, data = data_filtered) %>% 
  summary()
lm(tremor ~ CPZE + depression, data = data_filtered) %>% 
  summary()
lm(akathisia ~ CPZE + `Total score PANSS`, data = data_filtered) %>% 
  summary()
lm(`Total score SAS` ~ CPZE + `Total score PANSS`, data = data_filtered) %>% 
  summary()
```



`head rotation` ~ CPZE + visit + (1 | id)

tremor ~ CPZE + depression + visit + (1 | id)

akathisia ~ CPZE + `Total score PANSS` + visit + (1 | id)

`Total score SAS` ~ CPZE + `Total score PANSS` + visit + (1 | id)

```{r}
lmer(`head rotation` ~ CPZE + visit + (1 | id), data = data_filtered, REML = FALSE) %>% summary()
lmer(tremor ~ CPZE + depression + visit + (1 | id), data = data_filtered, REML = FALSE) %>% summary()
lmer(akathisia ~ CPZE + `Total score PANSS` + visit + (1 | id), data = data_filtered, REML = FALSE) %>% summary()
lmer(akathisia ~ CPZE + `Total score PANSS` + visit + (1 | id), data = data_filtered, REML = FALSE) %>% summary()
```
